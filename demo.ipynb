{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install openai\n",
    "!pip3 install python-dotenv\n",
    "!pip3 install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "\n",
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# simple OpenAI requests example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using OpenAI API BASE: https://oai-tvonment-chn.openai.azure.com/\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "import sys\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "openai.api_version = \"2023-03-15-preview\"\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "messages = [\n",
    "  \n",
    "]\n",
    "\n",
    "def ask_gpt(prompt):\n",
    "  messages.append({\"content\": prompt, \"role\": \"user\"})\n",
    "  response = openai.ChatCompletion.create(\n",
    "      engine=\"gpt-4\",\n",
    "      messages = messages,\n",
    "      temperature=1,\n",
    "      max_tokens=800,\n",
    "      top_p=0.95,\n",
    "      frequency_penalty=0,\n",
    "      presence_penalty=0,\n",
    "      stop=None)\n",
    "  message = response.choices[0].message\n",
    "  messages.append(message)\n",
    "  return message.content.strip()\n",
    "\n",
    "print(\"Using OpenAI API BASE: \" + openai.api_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# simple OpenAI example chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"\"\n",
    "while user_input != \"bye\":\n",
    "    user_input = input(\"You: \")\n",
    "    print(f\"You: {user_input}\\n\")\n",
    "    ai_response = ask_gpt(user_input)\n",
    "    print(f\"AI: {ai_response}\\n\")\n",
    "    sys.stdout.flush()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add Online Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = 'https://www.corporatesoftware.ch/blog/intelligent-host-schluss-mit-sicherheitslucken-bei-guest-usern/'\n",
    "response = requests.get(url)\n",
    "html = response.content.decode('utf-8')\n",
    "\n",
    "#print(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add chat function with Online Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "openai.api_version = \"2023-03-15-preview\"\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "messages = [{\"content\": html, \"role\": \"assistant\"}]\n",
    "\n",
    "def chat(prompt):\n",
    "  messages.append({\"content\": prompt, \"role\": \"user\"})\n",
    "  response = openai.ChatCompletion.create(\n",
    "      engine=\"gpt-4\",\n",
    "      messages = messages,\n",
    "      temperature=0.7,\n",
    "      max_tokens=800,\n",
    "      top_p=0.95,\n",
    "      frequency_penalty=0,\n",
    "      presence_penalty=0,\n",
    "      stop=None)\n",
    "  message = response.choices[0].message\n",
    "  messages.append(message)\n",
    "  return message.content.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chat with Online Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"\"\n",
    "while user_input != \"bye\":\n",
    "    user_input = input(\"You: \")\n",
    "    print(f\"You: {user_input}\\n\")\n",
    "    ai_response = chat(user_input)\n",
    "    print(f\"AI: {ai_response}\\n\")\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Azure OpenAI API BASE: https://oai-tvonment-chn.openai.azure.com/\n",
      "Using Azure AI Search endpoint: https://search-tvonment.search.windows.net/\n",
      "Using Azure AI Search index: index1\n",
      "Using Azure AI Search key: 8i5f4wZENWeR4IrEpBeQRb5fZ0cjbwqBr6Dxp4NqcYAzSeDLL2Ts\n"
     ]
    }
   ],
   "source": [
    "import openai, os, requests\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "# Azure OpenAI on your own data is only supported by the 2023-08-01-preview API version\n",
    "openai.api_version = \"2023-08-01-preview\"\n",
    "\n",
    "# Azure OpenAI setup\n",
    "openai.api_base = os.getenv(\"OPENAI_API_BASE\") # Add your endpoint here\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\") # Add your OpenAI API key here\n",
    "deployment_id = \"gpt-4\" # Add your deployment ID here\n",
    "\n",
    "# Azure AI Search setup\n",
    "search_endpoint = os.getenv(\"SEARCH_BASE\"); # Add your Azure AI Search endpoint here\n",
    "search_key = os.getenv(\"SEARCH_KEY\"); # Add your Azure AI Search admin key here\n",
    "search_index_name = \"index1\"; # Add your Azure AI Search index name here\n",
    "\n",
    "\n",
    "def setup_byod(deployment_id: str) -> None:\n",
    "    \"\"\"Sets up the OpenAI Python SDK to use your own data for the chat endpoint.\n",
    "\n",
    "    :param deployment_id: The deployment ID for the model to use with your own data.\n",
    "\n",
    "    To remove this configuration, simply set openai.requestssession to None.\n",
    "    \"\"\"\n",
    "\n",
    "    class BringYourOwnDataAdapter(requests.adapters.HTTPAdapter):\n",
    "\n",
    "        def send(self, request, **kwargs):\n",
    "            request.url = f\"{openai.api_base}/openai/deployments/{deployment_id}/extensions/chat/completions?api-version={openai.api_version}\"\n",
    "            return super().send(request, **kwargs)\n",
    "\n",
    "    session = requests.Session()\n",
    "\n",
    "    # Mount a custom adapter which will use the extensions endpoint for any call using the given `deployment_id`\n",
    "    session.mount(\n",
    "        prefix=f\"{openai.api_base}/openai/deployments/{deployment_id}\",\n",
    "        adapter=BringYourOwnDataAdapter()\n",
    "    )\n",
    "\n",
    "    openai.requestssession = session\n",
    "\n",
    "setup_byod(deployment_id)\n",
    "\n",
    "print(\"Using Azure OpenAI API BASE: \" + openai.api_base)\n",
    "print(\"Using Azure AI Search endpoint: \" + search_endpoint)\n",
    "print(\"Using Azure AI Search index: \" + search_index_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torturing puppies is generally considered ethically incorrect. From the viewpoint of ethics, causing unnecessary harm or suffering to sentient beings is generally seen as morally wrong. Furthermore, in the context of virtue ethics, actions like torturing puppies can be viewed as detrimental to one's character development[doc2]. Ethical theories like utilitarianism, deontology, and justice-based ethics also typically prohibit causing harm without justification, especially to animals who can experience suffering."
     ]
    }
   ],
   "source": [
    "\n",
    "message_text = [{\"role\": \"user\", \"content\": \"is it ethacally correct to torture puppies?\"}]\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "    messages=message_text,\n",
    "    deployment_id=deployment_id,\n",
    "    dataSources=[  # camelCase is intentional, as this is the format the API expects\n",
    "        {\n",
    "            \"type\": \"AzureCognitiveSearch\",\n",
    "            \"parameters\": {\n",
    "                \"endpoint\": search_endpoint,\n",
    "                \"indexName\": search_index_name,\n",
    "                \"semanticConfiguration\": \"default\",\n",
    "                \"queryType\": \"simple\",\n",
    "                \"fieldsMapping\": {},\n",
    "                \"inScope\": True,\n",
    "                \"roleInformation\": \"You are an AI assistant that helps people find information.\",\n",
    "                \"strictness\": 3,\n",
    "                \"topNDocuments\": 3,\n",
    "                \"key\": search_key\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    enhancements=\"undefined\",\n",
    "    temperature=0.7,\n",
    "    top_p=1,\n",
    "    max_tokens=2048,\n",
    "    stop=[\"\\n\"],\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for chunk in completion:\n",
    "    #print(chunk)\n",
    "    if hasattr(chunk.choices[0].delta, 'content'):\n",
    "        print(chunk.choices[0].delta.content, end=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
